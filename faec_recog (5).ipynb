{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faec_recog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "14D8o_iCwj8S",
        "outputId": "212bdfb9-77f8-45ca-edfb-a4be2015a2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.33.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvHEY7x_wpe6",
        "outputId": "e61a4314-4ea9-4ea1-fb2b-6b8d71140b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pip install pandas-ods-reader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas-ods-reader\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/f8/c1097f90411ec2cdfee9686c469a8acabff678185d761345975fc559c9fc/pandas_ods_reader-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-ods-reader) (4.2.6)\n",
            "Collecting ezodf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/c5/e966935c26d58d7e3d962270be61be972409084374d4093f478d1f82e8af/ezodf-0.3.2.tar.gz (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pandas-ods-reader) (1.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas-ods-reader) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas-ods-reader) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pandas-ods-reader) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->pandas-ods-reader) (1.15.0)\n",
            "Building wheels for collected packages: ezodf\n",
            "  Building wheel for ezodf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ezodf: filename=ezodf-0.3.2-py2.py3-none-any.whl size=49001 sha256=7cf06e92a6f2997dbb45dacc9cbc1d2adb4cb4bd860b7b4a5e5c45b8dee00d78\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/6c/f9/107d39d45441980bf273757eba003ef057c6193c9d7650fac7\n",
            "Successfully built ezodf\n",
            "Installing collected packages: ezodf, pandas-ods-reader\n",
            "Successfully installed ezodf-0.3.2 pandas-ods-reader-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj6yPmsi2oZO",
        "outputId": "f18388ad-0fed-49fd-c341-f6e2c04a2fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "pip install unrar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unrar\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/0b/53130ccd483e3db8c8a460cb579bdb21b458d5494d67a261e1a5b273fbb9/unrar-0.4-py3-none-any.whl\n",
            "Installing collected packages: unrar\n",
            "Successfully installed unrar-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFYH7Udn3IKU",
        "outputId": "88214fa8-57fe-4038-e2a4-959b99fbbf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "pip install pyunpack"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/ca/00c8767568924e5c2209da99b6abdeeed9d11cbae2a713d54d041b092a09/entrypoint2-0.2.3-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: argparse, entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.3 pyunpack-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhzBfMTK3Kec",
        "outputId": "4d6934cc-7a5d-47d1-9617-b82bd8b5d43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "pip install patool"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGq6bPKK3RHk"
      },
      "source": [
        "from pyunpack import Archive\n",
        "Archive('mrlEyes_2018_01.rar').extractall('sample_data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2JK1U6BWm04",
        "outputId": "860fa673-5d93-4553-a041-b3c3c9996edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "pip install keras_preprocessing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_preprocessing) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHPQq_GBw4mx",
        "outputId": "e491c81e-674a-4261-b02a-9506732f9530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "from pandas_ods_reader import read_ods\n",
        "import ezodf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "class Dataset():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.path = \"sample_data/mrlEyes_2018_01/\"\n",
        "        self.X_train = None\n",
        "        self.Y_train = None\n",
        "        self.X_test = None\n",
        "        self.Y_test = None\n",
        "        self.IMG_SIZE = 64\n",
        "        self.df = None\n",
        "\n",
        "    def read_ods(self, header):\n",
        "        doc = ezodf.opendoc(self.path+\"stats_2018_01.ods\").sheets[0]\n",
        "        # sheet = doc.sheets\n",
        "        # df_dict = {}\n",
        "\n",
        "        return pd.DataFrame({col[header].value: [x.value for x in col[header + 1:]]\n",
        "                             for col in doc.columns()})\n",
        "    \n",
        "    def make_dataset(self):\n",
        "        temp = []\n",
        "        data = []\n",
        "        for root, dirs, files in os.walk(self.path):\n",
        "            for file in files:\n",
        "                if file is not None:\n",
        "                    temp.append(file)\n",
        "\n",
        "        for file in temp:\n",
        "\n",
        "            if file == 'annotation.txt':\n",
        "                temp.remove(file)\n",
        "            if file == 'stats_2018_01.ods':\n",
        "                temp.remove(file)\n",
        "\n",
        "        for i, file_dt in enumerate(temp):\n",
        "            index = i\n",
        "            label = file_dt.split(\"_\")[4]\n",
        "            img_name = file_dt\n",
        "            folder = file_dt.split(\"_\")[0]\n",
        "            filename = folder + \"/\" + img_name\n",
        "            img = cv2.imread(os.path.join(self.path, filename))\n",
        "            # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            # new_img = cv2.resize(gray, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "            # cv2.imshow(\"Image\",new_img)\n",
        "            # cv2.waitKey(0)\n",
        "            # print(new_img.shape)\n",
        "            pair = [index, img_name, label, folder]\n",
        "            data.append(pair)\n",
        "        self.df = pd.DataFrame(data, columns=[\"Index\", \"Image\", \"Eye_state\", \"Folder\"])\n",
        "        self.df.index = self.df[\"Index\"]\n",
        "        # return self.df\n",
        "\n",
        "    def traintest_split_data(self):\n",
        "        # self.df.drop(self.df.columns[0], axis=1)\n",
        "        # print(self.df)\n",
        "        X = self.df[\"Image\"]\n",
        "        # Y = self.df[\"Eye_state\"]\n",
        "        folder = self.df[\"Folder\"]\n",
        "        # X_new = []\n",
        "\n",
        "        # for i, image in enumerate(X):\n",
        "        #     filename = folder[i] + \"/\" + image\n",
        "\n",
        "        #     img = cv2.imread(os.path.join(self.path, filename))\n",
        "        #     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        #     new_img = cv2.resize(gray, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "        #     # cv2.imshow(\"Image\",new_img)\n",
        "        #     # cv2.waitKey(0)\n",
        "        #     # print(new_img.shape)\n",
        "        #     X_new.append(new_img)\n",
        "\n",
        "        temp_train_data , test_data = train_test_split(self.df, test_size = 0.1, shuffle=False)\n",
        "        train_data , val_data = train_test_split(temp_train_data, test_size = 0.1, shuffle=False)\n",
        "        print(train_data)\n",
        "        print(test_data)\n",
        "        print(val_data)\n",
        "\n",
        "        # train_dir = \"Train\"\n",
        "        # test_dir = \"Test\"\n",
        "        # os.mkdir(os.path.join(self.path, train_dir))\n",
        "        # os.mkdir(os.path.join(self.path, test_dir))\n",
        "        for i, im_name_tr in enumerate(train_data[\"Image\"]):\n",
        "            if i != 0:\n",
        "                if train_data.loc[i][\"Eye_state\"] == '1':\n",
        "                    img_fold = train_data.loc[i][\"Folder\"] + '/' + im_name_tr\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "                    # new_imag = cv2.cvtColor(imag, cv2.COLOR_BGR2GRAY)\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Train_data1/1/'+im_name_tr,wr_imag)\n",
        "                if train_data.loc[i][\"Eye_state\"] == '0':\n",
        "                    img_fold = train_data[\"Folder\"][i] + '/' + im_name_tr\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "                    # new_imag = cv2.cvtColor(imag, cv2.COLOR_BGR2GRAY)\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Train_data1/0/'+im_name_tr,wr_imag)\n",
        "            \n",
        "        for j in range(test_data.index[0],test_data.index[-1]):\n",
        "            if j != 0:\n",
        "                if test_data.loc[j][\"Eye_state\"] == '1':\n",
        "                    im_name_t = test_data.loc[j][\"Image\"]\n",
        "                    img_fold = test_data.loc[j][\"Folder\"] + '/' + im_name_t\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "                    # new_imag = cv2.cvtColor(imag, cv2.COLOR_BGR2GRAY)\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Test_data1/1/'+im_name_t,wr_imag)\n",
        "                if test_data.loc[j][\"Eye_state\"] == '0':\n",
        "                    im_name_t = test_data.loc[j][\"Image\"]\n",
        "                    img_fold = test_data.loc[j][\"Folder\"] + '/' + im_name_t\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "                    # new_imag = cv2.cvtColor(imag, cv2.COLOR_BGR2GRAY)\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Test_data1/0/'+im_name_t,wr_imag)\n",
        "        \n",
        "        for k in range(val_data.index[0],val_data.index[-1]):\n",
        "            if k != 0:\n",
        "                if val_data.loc[k][\"Eye_state\"] == '1':\n",
        "                    im_name_v = val_data.loc[k][\"Image\"]\n",
        "                    img_fold = val_data.loc[k][\"Folder\"] + '/' + im_name_v\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "                    # new_imag = cv2.cvtColor(imag, cv2.COLOR_BGR2GRAY)\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Val_data1/1/'+im_name_v,wr_imag)\n",
        "                if val_data.loc[k][\"Eye_state\"] == '0':\n",
        "                    im_name_v = val_data.loc[k][\"Image\"]\n",
        "                    img_fold = val_data.loc[k][\"Folder\"] + '/' + im_name_v\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "                    # new_imag = cv2.cvtColor(imag, cv2.COLOR_BGR2GRAY)\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Val_data1/0/'+im_name_v,wr_imag)\n",
        "        \n",
        "        return train_data, val_data, test_data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = Dataset()\n",
        "    # df = data.create_dataset(header=0)\n",
        "    df = data.make_dataset()\n",
        "    train_data, val_data, test_data = data.traintest_split_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Index                         Image Eye_state Folder\n",
            "Index                                                      \n",
            "0          0  s0013_02028_0_1_0_0_0_01.png         0  s0013\n",
            "1          1  s0013_00130_0_0_0_0_0_01.png         0  s0013\n",
            "2          2  s0013_01585_0_0_0_0_0_01.png         0  s0013\n",
            "3          3  s0013_00201_0_0_0_0_0_01.png         0  s0013\n",
            "4          4  s0013_02346_0_1_0_0_0_01.png         0  s0013\n",
            "...      ...                           ...       ...    ...\n",
            "68762  68762  s0029_00482_0_0_1_0_1_01.png         1  s0029\n",
            "68763  68763  s0029_00851_0_0_1_0_1_01.png         1  s0029\n",
            "68764  68764  s0029_00053_0_0_0_0_0_01.png         0  s0029\n",
            "68765  68765  s0029_01078_0_0_1_0_1_01.png         1  s0029\n",
            "68766  68766  s0029_00275_0_0_1_0_1_01.png         1  s0029\n",
            "\n",
            "[68767 rows x 4 columns]\n",
            "       Index                         Image Eye_state Folder\n",
            "Index                                                      \n",
            "76408  76408  s0037_03460_1_1_0_2_0_01.png         0  s0037\n",
            "76409  76409  s0037_02716_1_0_0_0_0_01.png         0  s0037\n",
            "76410  76410  s0037_01739_1_0_0_0_0_01.png         0  s0037\n",
            "76411  76411  s0037_06775_1_0_1_0_0_01.png         1  s0037\n",
            "76412  76412  s0037_09660_1_1_1_0_0_01.png         1  s0037\n",
            "...      ...                           ...       ...    ...\n",
            "84893  84893  s0022_00321_0_1_1_2_1_01.png         1  s0022\n",
            "84894  84894  s0022_00057_0_0_0_0_1_01.png         0  s0022\n",
            "84895  84895  s0022_00004_0_0_0_0_1_01.png         0  s0022\n",
            "84896  84896  s0022_00374_0_1_1_2_1_01.png         1  s0022\n",
            "84897  84897  s0022_00259_0_0_1_0_1_01.png         1  s0022\n",
            "\n",
            "[8490 rows x 4 columns]\n",
            "       Index                         Image Eye_state Folder\n",
            "Index                                                      \n",
            "68767  68767  s0029_01390_0_0_1_0_1_01.png         1  s0029\n",
            "68768  68768  s0029_00246_0_0_1_0_1_01.png         1  s0029\n",
            "68769  68769  s0029_01081_0_0_1_0_1_01.png         1  s0029\n",
            "68770  68770  s0029_00051_0_0_0_0_0_01.png         0  s0029\n",
            "68771  68771  s0029_00426_0_0_1_0_1_01.png         1  s0029\n",
            "...      ...                           ...       ...    ...\n",
            "76403  76403  s0037_09530_1_1_1_2_0_01.png         1  s0037\n",
            "76404  76404  s0037_00088_1_0_0_0_0_01.png         0  s0037\n",
            "76405  76405  s0037_04350_1_1_0_0_0_01.png         0  s0037\n",
            "76406  76406  s0037_07065_1_0_1_0_1_01.png         1  s0037\n",
            "76407  76407  s0037_06849_1_0_1_0_0_01.png         1  s0037\n",
            "\n",
            "[7641 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkeaaalqxQIb",
        "outputId": "65029ec8-629b-411c-ee82-c0b42ea36fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy, binary_crossentropy\n",
        "from keras.models import save_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "# from Dataset import Dataset\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, batch_size, epochs):\n",
        "        self.model = None\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.inputshape = (64,64,3)\n",
        "        self.STEP_SIZE_TRAIN = None\n",
        "        self.STEP_SIZE_VALID = None\n",
        "        self.STEP_SIZE_TEST = None\n",
        "\n",
        "    def build_model(self):\n",
        "        self.model = Sequential()\n",
        "\n",
        "        self.model.add(Conv2D(32, (3,3), strides=2, input_shape=self.inputshape))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        self.model.add(Conv2D(64, (3, 3), strides=2))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        self.model.add(Conv2D(256, (3, 3), strides=2))\n",
        "        self.model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        self.model.add(Flatten())\n",
        "\n",
        "        self.model.add(Dense(512, activation='relu'))\n",
        "        self.model.add(Dense(256, activation='relu'))\n",
        "\n",
        "        self.model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # return self.model\n",
        "\n",
        "    def build_on_resnet(self):\n",
        "        self.model = Sequential()\n",
        "        \n",
        "        self.base_model = ResNet50(input_shape=self.inputshape, include_top=False, weights=\"imagenet\")\n",
        "\n",
        "        for l in self.base_model.layers:\n",
        "            l.trainable = False\n",
        "\n",
        "        self.model.add(self.base_model)\n",
        "\n",
        "        # conv1 = Conv2D(256, (1, 1), strides=2)(self.base_model.output)\n",
        "        # pool1 = MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "        # act1 = Activation('relu')(pool1)\n",
        "        \n",
        "        self.model.add(Flatten())\n",
        "\n",
        "        self.model.add(Dense(512, activation='relu'))\n",
        "        self.model.add(Dense(256, activation='relu'))\n",
        "\n",
        "        self.model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # self.model = Model(inputs=self.base_model, outputs=dense3)\n",
        "    \n",
        "    def train_model(self, X_train, Y_train):\n",
        "\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "        #                       patience=2, min_lr=0.0000001,cooldown=1)\n",
        "        # checkpoint_best = callbacks.ModelCheckpoint(filepath='sample_data/best_model.h5', monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "        self.model.fit(X_train, Y_train, batch_size=self.batch_size, epochs=self.epochs)\n",
        "\n",
        "        print(\"Model Trained\")\n",
        "\n",
        "    def train_model_fit(self, train_data, val_data, callback):\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        self.model.fit(train_data, steps_per_epoch=self.STEP_SIZE_TRAIN, epochs=self.epochs, \n",
        "                       validation_data=val_data, validation_steps=self.STEP_SIZE_VALID, callbacks=callback)\n",
        "    \n",
        "    def train_model_gen(self, train_gen, val_gen):\n",
        "\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        self.model.fit_generator(generator=train_gen, steps_per_epoch=self.STEP_SIZE_TRAIN,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=self.STEP_SIZE_VALID,\n",
        "                    epochs=self.epochs)\n",
        "\n",
        "    def evaluate_model(self, X_test, Y_test):\n",
        "\n",
        "        loss, accuracy = self.model.evaluate(X_test, Y_test, batch_size=self.batch_size)\n",
        "        print(\"Loss: \"+str(loss))\n",
        "        print(\"Accuracy: \"+str(accuracy))\n",
        "\n",
        "    def evaluate_model_gen(self, test_gen):\n",
        "\n",
        "        self.model.evaluate_generator(generator=test_gen,steps=self.STEP_SIZE_VALID)\n",
        "\n",
        "    def evaluate_new(self, test_gen):\n",
        "\n",
        "        self.model.evaluate(generator=test_gen,steps=self.STEP_SIZE_VALID)\n",
        "\n",
        "    def save(self):\n",
        "\n",
        "        self.model.save('sample_data/mrlEyes_2018_01/model.h5')\n",
        "        print(\"Model Saved\")\n",
        "\n",
        "    def predict(self, image):\n",
        "\n",
        "        image = image.reshape((1,1, 80, 80))\n",
        "        image.astype('Float32')\n",
        "        image /= 255.0\n",
        "\n",
        "        result = self.model.predict_proba(image)\n",
        "        max_index = np.argmax(result)\n",
        "\n",
        "        return max_index, result[0](max_index)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('TensorFlow version:', tf.__version__)\n",
        "    print('Is using GPU?', tf.test.is_gpu_available())\n",
        "\n",
        "    from tensorflow.python.client import device_lib\n",
        "\n",
        "    # def get_available_devices():\n",
        "    #     local_device_protos = device_lib.list_local_devices()\n",
        "    #     return [x.name for x in local_device_protos]\n",
        "\n",
        "    # print(get_available_devices())\n",
        "\n",
        "    # with tf.device('/device:XLA_GPU:0'):\n",
        "\n",
        "    model = Model(epochs=20, batch_size=32)\n",
        "    # data = Dataset()\n",
        "    # data.make_dataset()\n",
        "    # train_data, val_data, test_data = data.traintest_split_data()\n",
        "    # model.inputshape = (64, 64, 1)\n",
        "    \n",
        "    data_gen = ImageDataGenerator(rescale=1./255.)\n",
        "    train_gen = data_gen.flow_from_directory(directory=r\"sample_data/mrlEyes_2018_01/Train_data1/\",\n",
        "                                              target_size=(64, 64),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32,\n",
        "                                              classes = ['1', '0'],\n",
        "                                              class_mode=\"binary\",\n",
        "                                              shuffle=True)\n",
        "\n",
        "    val_gen = data_gen.flow_from_directory(directory=r\"sample_data/mrlEyes_2018_01/Val_data1/\",\n",
        "                                              target_size=(64, 64),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32,\n",
        "                                              classes = ['1', '0'],\n",
        "                                              class_mode=\"binary\",\n",
        "                                              shuffle=True)\n",
        "    \n",
        "    test_gen = data_gen.flow_from_directory(directory=r\"sample_data/mrlEyes_2018_01/Test_data1/\",\n",
        "                                              target_size=(64, 64),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32,\n",
        "                                              classes = ['1', '0'],\n",
        "                                              class_mode=None,\n",
        "                                              shuffle=False)\n",
        "\n",
        "    STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
        "    STEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n",
        "    STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
        "\n",
        "    model.STEP_SIZE_TRAIN = STEP_SIZE_TRAIN\n",
        "    model.STEP_SIZE_VALID = STEP_SIZE_VALID\n",
        "    model.STEP_SIZE_TEST = STEP_SIZE_TEST\n",
        "\n",
        "    callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0000001,cooldown=1)\n",
        "    checkpoint_best = callbacks.ModelCheckpoint(filepath='sample_data/mrlEyes_2018_01/best_model.h5', monitor=\"val_accuracy\", save_best_only=True)\n",
        "    callbacks = [callback_lr, checkpoint_best]\n",
        "\n",
        "    # model.build_model()\n",
        "    # model.train_model_gen(train_gen, val_gen)\n",
        "    model.build_on_resnet()\n",
        "    model.train_model_fit(train_gen, val_gen, callbacks)\n",
        "    # model.evaluate_model_gen(test_gen)\n",
        "    # model.evaluate_new(test_gen)\n",
        "    # model.save()\n",
        "\n",
        "    # model = load_model(\"best_model.h5\")\n",
        "    # model.predict()\n",
        "    # model.evaluate_new(val_gen)\n",
        "    # model.save()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2148/2148 [==============================] - 1113s 518ms/step - loss: 0.4818 - accuracy: 0.7695 - val_loss: 0.4490 - val_accuracy: 0.8048\n",
            "2148/2148 [==============================] - 1113s 518ms/step - loss: 0.4818 - accuracy: 0.7695 - val_loss: 0.4490 - val_accuracy: 0.8048\n",
            "Epoch 2/20\n",
            "Epoch 2/20\n",
            "2148/2148 [==============================] - 1107s 515ms/step - loss: 0.3592 - accuracy: 0.8493 - val_loss: 0.3941 - val_accuracy: 0.8243\n",
            "2148/2148 [==============================] - 1107s 515ms/step - loss: 0.3592 - accuracy: 0.8493 - val_loss: 0.3941 - val_accuracy: 0.8243\n",
            "Epoch 3/20\n",
            "Epoch 3/20\n",
            "2148/2148 [==============================] - 1104s 514ms/step - loss: 0.3196 - accuracy: 0.8694 - val_loss: 0.5056 - val_accuracy: 0.7483\n",
            "2148/2148 [==============================] - 1104s 514ms/step - loss: 0.3196 - accuracy: 0.8694 - val_loss: 0.5056 - val_accuracy: 0.7483\n",
            "Epoch 4/20\n",
            "Epoch 4/20\n",
            "2148/2148 [==============================] - 1105s 515ms/step - loss: 0.2952 - accuracy: 0.8809 - val_loss: 0.3818 - val_accuracy: 0.8342\n",
            "2148/2148 [==============================] - 1105s 515ms/step - loss: 0.2952 - accuracy: 0.8809 - val_loss: 0.3818 - val_accuracy: 0.8342\n",
            "Epoch 5/20\n",
            "Epoch 5/20\n",
            "2148/2148 [==============================] - 1103s 514ms/step - loss: 0.2801 - accuracy: 0.8871 - val_loss: 0.4973 - val_accuracy: 0.7782\n",
            "2148/2148 [==============================] - 1103s 514ms/step - loss: 0.2801 - accuracy: 0.8871 - val_loss: 0.4973 - val_accuracy: 0.7782\n",
            "Epoch 6/20\n",
            "Epoch 6/20\n",
            "2148/2148 [==============================] - 1104s 514ms/step - loss: 0.2655 - accuracy: 0.8942 - val_loss: 0.3433 - val_accuracy: 0.8557\n",
            "2148/2148 [==============================] - 1104s 514ms/step - loss: 0.2655 - accuracy: 0.8942 - val_loss: 0.3433 - val_accuracy: 0.8557\n",
            "Epoch 7/20\n",
            "Epoch 7/20\n",
            "2148/2148 [==============================] - 1107s 515ms/step - loss: 0.2533 - accuracy: 0.8998 - val_loss: 0.3480 - val_accuracy: 0.8498\n",
            "2148/2148 [==============================] - 1107s 515ms/step - loss: 0.2533 - accuracy: 0.8998 - val_loss: 0.3480 - val_accuracy: 0.8498\n",
            "Epoch 8/20\n",
            "Epoch 8/20\n",
            "2148/2148 [==============================] - 1106s 515ms/step - loss: 0.2398 - accuracy: 0.9060 - val_loss: 0.3289 - val_accuracy: 0.8588\n",
            "2148/2148 [==============================] - 1106s 515ms/step - loss: 0.2398 - accuracy: 0.9060 - val_loss: 0.3289 - val_accuracy: 0.8588\n",
            "Epoch 9/20\n",
            "Epoch 9/20\n",
            "2148/2148 [==============================] - 1109s 516ms/step - loss: 0.2333 - accuracy: 0.9083 - val_loss: 0.3368 - val_accuracy: 0.8560\n",
            "2148/2148 [==============================] - 1109s 516ms/step - loss: 0.2333 - accuracy: 0.9083 - val_loss: 0.3368 - val_accuracy: 0.8560\n",
            "Epoch 10/20\n",
            "Epoch 10/20\n",
            "2148/2148 [==============================] - 1109s 516ms/step - loss: 0.2214 - accuracy: 0.9138 - val_loss: 0.3522 - val_accuracy: 0.8491\n",
            "2148/2148 [==============================] - 1109s 516ms/step - loss: 0.2214 - accuracy: 0.9138 - val_loss: 0.3522 - val_accuracy: 0.8491\n",
            "Epoch 11/20\n",
            "Epoch 11/20\n",
            "2148/2148 [==============================] - 1110s 517ms/step - loss: 0.1944 - accuracy: 0.9278 - val_loss: 0.4280 - val_accuracy: 0.8034\n",
            "2148/2148 [==============================] - 1110s 517ms/step - loss: 0.1944 - accuracy: 0.9278 - val_loss: 0.4280 - val_accuracy: 0.8034\n",
            "Epoch 12/20\n",
            "Epoch 12/20\n",
            "2148/2148 [==============================] - 1111s 517ms/step - loss: 0.1911 - accuracy: 0.9284 - val_loss: 0.3573 - val_accuracy: 0.8470\n",
            "2148/2148 [==============================] - 1111s 517ms/step - loss: 0.1911 - accuracy: 0.9284 - val_loss: 0.3573 - val_accuracy: 0.8470\n",
            "Epoch 13/20\n",
            "Epoch 13/20\n",
            "2148/2148 [==============================] - 1110s 517ms/step - loss: 0.1838 - accuracy: 0.9316 - val_loss: 0.3462 - val_accuracy: 0.8569\n",
            "2148/2148 [==============================] - 1110s 517ms/step - loss: 0.1838 - accuracy: 0.9316 - val_loss: 0.3462 - val_accuracy: 0.8569\n",
            "Epoch 14/20\n",
            "Epoch 14/20\n",
            "2148/2148 [==============================] - 1110s 517ms/step - loss: 0.1828 - accuracy: 0.9321 - val_loss: 0.3419 - val_accuracy: 0.8596\n",
            "2148/2148 [==============================] - 1110s 517ms/step - loss: 0.1828 - accuracy: 0.9321 - val_loss: 0.3419 - val_accuracy: 0.8596\n",
            "Epoch 15/20\n",
            "Epoch 15/20\n",
            "2148/2148 [==============================] - 1113s 518ms/step - loss: 0.1807 - accuracy: 0.9329 - val_loss: 0.3383 - val_accuracy: 0.8628\n",
            "2148/2148 [==============================] - 1113s 518ms/step - loss: 0.1807 - accuracy: 0.9329 - val_loss: 0.3383 - val_accuracy: 0.8628\n",
            "Epoch 16/20\n",
            "Epoch 16/20\n",
            "2148/2148 [==============================] - 1111s 517ms/step - loss: 0.1806 - accuracy: 0.9329 - val_loss: 0.3452 - val_accuracy: 0.8571\n",
            "2148/2148 [==============================] - 1111s 517ms/step - loss: 0.1806 - accuracy: 0.9329 - val_loss: 0.3452 - val_accuracy: 0.8571\n",
            "Epoch 17/20\n",
            "Epoch 17/20\n",
            "2148/2148 [==============================] - 1103s 514ms/step - loss: 0.1802 - accuracy: 0.9334 - val_loss: 0.3446 - val_accuracy: 0.8573\n",
            "2148/2148 [==============================] - 1103s 514ms/step - loss: 0.1802 - accuracy: 0.9334 - val_loss: 0.3446 - val_accuracy: 0.8573\n",
            "Epoch 18/20\n",
            "Epoch 18/20\n",
            "2148/2148 [==============================] - 1152s 536ms/step - loss: 0.1801 - accuracy: 0.9335 - val_loss: 0.3450 - val_accuracy: 0.8569\n",
            "2148/2148 [==============================] - 1152s 536ms/step - loss: 0.1801 - accuracy: 0.9335 - val_loss: 0.3450 - val_accuracy: 0.8569\n",
            "Epoch 19/20\n",
            "Epoch 19/20\n",
            "2148/2148 [==============================] - 1137s 529ms/step - loss: 0.1801 - accuracy: 0.9334 - val_loss: 0.3455 - val_accuracy: 0.8573\n",
            "2148/2148 [==============================] - 1137s 529ms/step - loss: 0.1801 - accuracy: 0.9334 - val_loss: 0.3455 - val_accuracy: 0.8573\n",
            "Epoch 20/20\n",
            "Epoch 20/20\n",
            "2148/2148 [==============================] - 1140s 531ms/step - loss: 0.1801 - accuracy: 0.9337 - val_loss: 0.3431 - val_accuracy: 0.8595\n",
            "2148/2148 [==============================] - 1140s 531ms/step - loss: 0.1801 - accuracy: 0.9337 - val_loss: 0.3431 - val_accuracy: 0.8595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-44df06f65f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# model = load_model(\"best_model.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# model.predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;31m# model.save()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: evaluate_new() got an unexpected keyword argument 'x'"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-44df06f65f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# model = load_model(\"best_model.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# model.predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;31m# model.save()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: evaluate_new() got an unexpected keyword argument 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wimjlIjawMY2",
        "outputId": "5c37796f-2102-4d94-e8d4-626d5c285522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = load_model('sample_data/mrlEyes_2018_01/best_model.h5')\n",
        "model.evaluate(x=val_gen, steps=STEP_SIZE_VALID)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "238/238 [==============================] - 108s 455ms/step - loss: 0.3383 - accuracy: 0.8627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.338301420211792, 0.8626575469970703]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qImWtnmg38jm",
        "outputId": "e629be9a-109e-4f4f-ee0d-d1f9c28b53e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds = model.predict(x=test_gen, verbose=1, steps=STEP_SIZE_TEST)\n",
        "actual = test_gen.classes\n",
        "file = open(\"results_new.txt\", 'w+')\n",
        "for i in range(len(preds)):\n",
        "    val = (preds[i][0], actual[i])\n",
        "    file.write(str(val))\n",
        "file.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "265/265 [==============================] - 121s 458ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsXLB-0i8ScQ",
        "outputId": "6c59db1e-2543-45c5-e523-ab7ffdd0fa65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "pip install matplotlib"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9y6O6ekry9r",
        "outputId": "468ab165-5d3c-48a4-90a1-00868020825b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(40,40))\n",
        "\n",
        "loses = pd.DataFrame(model.history.history)\n",
        "# loses.plot()\n",
        "loses.info()\n",
        "# vloses = pd.DataFrame(model.history.history['val_loss'])\n",
        "# vloses.plot()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 0 entries\n",
            "Empty DataFrame"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2880x2880 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE5JhTp4sE0w",
        "outputId": "99021116-e9a3-4bb8-c7a2-022f942d5af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a82222783078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaS9QTHJsJ8Q"
      },
      "source": [
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}