{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a99UmDSKK9B"
      },
      "source": [
        "! pip install tensorflow-gpu\n",
        "! pip install pandas-ods-reader\n",
        "! pip install pyunpack\n",
        "! pip install patool\n",
        "! pip install keras_preprocessing\n",
        "! pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B8P5sTmK578"
      },
      "source": [
        "from pyunpack import Archive\n",
        "Archive('mrlEyes_2018_01.rar').extractall('sample_data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIgfPI8fKgn8"
      },
      "source": [
        "############# Data Cleaning and Preprocessing #######################\n",
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "from pandas_ods_reader import read_ods\n",
        "import ezodf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "class Dataset():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.path = \"sample_data/mrlEyes_2018_01/\"\n",
        "        self.X_train = None\n",
        "        self.Y_train = None\n",
        "        self.X_test = None\n",
        "        self.Y_test = None\n",
        "        self.IMG_SIZE = 64\n",
        "        self.df = None\n",
        "\n",
        "    def read_ods(self, header):\n",
        "        doc = ezodf.opendoc(self.path+\"stats_2018_01.ods\").sheets[0]\n",
        "\n",
        "        return pd.DataFrame({col[header].value: [x.value for x in col[header + 1:]]\n",
        "                             for col in doc.columns()})\n",
        "    \n",
        "    def make_dataset(self):\n",
        "        temp = []\n",
        "        data = []\n",
        "        for root, dirs, files in os.walk(self.path):\n",
        "            for file in files:\n",
        "                if file is not None:\n",
        "                    temp.append(file)\n",
        "\n",
        "        for file in temp:\n",
        "\n",
        "            if file == 'annotation.txt':\n",
        "                temp.remove(file)\n",
        "            if file == 'stats_2018_01.ods':\n",
        "                temp.remove(file)\n",
        "\n",
        "        for i, file_dt in enumerate(temp):\n",
        "            index = i\n",
        "            label = file_dt.split(\"_\")[4]\n",
        "            img_name = file_dt\n",
        "            folder = file_dt.split(\"_\")[0]\n",
        "            filename = folder + \"/\" + img_name\n",
        "            img = cv2.imread(os.path.join(self.path, filename))\n",
        "\n",
        "            pair = [index, img_name, label, folder]\n",
        "            data.append(pair)\n",
        "        self.df = pd.DataFrame(data, columns=[\"Index\", \"Image\", \"Eye_state\", \"Folder\"])\n",
        "        self.df.index = self.df[\"Index\"]\n",
        "\n",
        "    def traintest_split_data(self):\n",
        "        # self.df.drop(self.df.columns[0], axis=1)\n",
        "        X = self.df[\"Image\"]\n",
        "        # Y = self.df[\"Eye_state\"]\n",
        "        folder = self.df[\"Folder\"]\n",
        "\n",
        "        temp_train_data , test_data = train_test_split(self.df, test_size = 0.1, shuffle=False)\n",
        "        train_data , val_data = train_test_split(temp_train_data, test_size = 0.1, shuffle=False)\n",
        "        print(train_data)\n",
        "        print(test_data)\n",
        "        print(val_data)\n",
        "\n",
        "        # train_dir = \"sample_data/mrlEyes_2018_01/Train_data1\"\n",
        "        # test_dir = \"sample_data/mrlEyes_2018_01/Test_data1\"\n",
        "        # val_dir = \"sample_data/mrlEyes_2018_01/Val_data1\"\n",
        "        \n",
        "        # os.mkdir(train_dir)\n",
        "        # os.mkdir(test_dir)\n",
        "        # os.mkdir(val_dir)\n",
        "        \n",
        "        # class_1 = \"1\"\n",
        "        # class_0 = \"0\"\n",
        "\n",
        "        # os.mkdir(os.path.join(train_dir, class_1))\n",
        "        # os.mkdir(os.path.join(train_dir, class_0))\n",
        "        # os.mkdir(os.path.join(test_dir, class_1))\n",
        "        # os.mkdir(os.path.join(test_dir, class_0))\n",
        "        # os.mkdir(os.path.join(val_dir, class_1))\n",
        "        # os.mkdir(os.path.join(val_dir, class_0))\n",
        "\n",
        "        for i, im_name_tr in enumerate(train_data[\"Image\"]):\n",
        "            if i != 0:\n",
        "                if train_data.loc[i][\"Eye_state\"] == '1':\n",
        "                    img_fold = train_data.loc[i][\"Folder\"] + '/' + im_name_tr\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Train_data1/1/'+im_name_tr,wr_imag)\n",
        "                if train_data.loc[i][\"Eye_state\"] == '0':\n",
        "                    img_fold = train_data[\"Folder\"][i] + '/' + im_name_tr\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Train_data1/0/'+im_name_tr,wr_imag)\n",
        "            \n",
        "        for j in range(test_data.index[0],test_data.index[-1]):\n",
        "            if j != 0:\n",
        "                if test_data.loc[j][\"Eye_state\"] == '1':\n",
        "                    im_name_t = test_data.loc[j][\"Image\"]\n",
        "                    img_fold = test_data.loc[j][\"Folder\"] + '/' + im_name_t\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Test_data1/1/'+im_name_t,wr_imag)\n",
        "                if test_data.loc[j][\"Eye_state\"] == '0':\n",
        "                    im_name_t = test_data.loc[j][\"Image\"]\n",
        "                    img_fold = test_data.loc[j][\"Folder\"] + '/' + im_name_t\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Test_data1/0/'+im_name_t,wr_imag)\n",
        "        \n",
        "        for k in range(val_data.index[0],val_data.index[-1]):\n",
        "            if k != 0:\n",
        "                if val_data.loc[k][\"Eye_state\"] == '1':\n",
        "                    im_name_v = val_data.loc[k][\"Image\"]\n",
        "                    img_fold = val_data.loc[k][\"Folder\"] + '/' + im_name_v\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Val_data1/1/'+im_name_v,wr_imag)\n",
        "                if val_data.loc[k][\"Eye_state\"] == '0':\n",
        "                    im_name_v = val_data.loc[k][\"Image\"]\n",
        "                    img_fold = val_data.loc[k][\"Folder\"] + '/' + im_name_v\n",
        "                    dir = self.path + '/' + img_fold\n",
        "                    imag = cv2.imread(dir)\n",
        "\n",
        "                    new_imag1 = cv2.resize(imag, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                    new_imag = cv2.cvtColor(new_imag1, cv2.COLOR_BGR2GRAY)\n",
        "                    wr_imag = np.zeros((64,64,3))\n",
        "                    wr_imag[:,:,0] = new_imag\n",
        "                    wr_imag[:,:,1] = new_imag\n",
        "                    wr_imag[:,:,2] = new_imag\n",
        "                    cv2.imwrite('sample_data/mrlEyes_2018_01/Val_data1/0/'+im_name_v,wr_imag)\n",
        "        \n",
        "        return train_data, val_data, test_data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = Dataset()\n",
        "    # df = data.create_dataset(header=0)\n",
        "    df = data.make_dataset()\n",
        "    train_data, val_data, test_data = data.traintest_split_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zmNKuFbMFVs"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy, binary_crossentropy\n",
        "from keras.models import save_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, batch_size, epochs):\n",
        "        self.model = None\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.inputshape = (64,64,3)\n",
        "        self.STEP_SIZE_TRAIN = None\n",
        "        self.STEP_SIZE_VALID = None\n",
        "        self.STEP_SIZE_TEST = None\n",
        "\n",
        "    def build_model(self):\n",
        "        self.model = Sequential()\n",
        "\n",
        "        self.model.add(Conv2D(32, (3,3), strides=2, input_shape=self.inputshape))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        self.model.add(Conv2D(64, (3, 3), strides=2))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        self.model.add(Conv2D(256, (3, 3), strides=2))\n",
        "        self.model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        self.model.add(Flatten())\n",
        "\n",
        "        self.model.add(Dense(512, activation='relu'))\n",
        "        self.model.add(Dense(256, activation='relu'))\n",
        "\n",
        "        self.model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        # return self.model\n",
        "\n",
        "    def build_on_resnet(self):\n",
        "        self.model = Sequential()\n",
        "        \n",
        "        self.base_model = ResNet50(input_shape=self.inputshape, include_top=False, weights=\"imagenet\")\n",
        "\n",
        "        for l in self.base_model.layers:\n",
        "            l.trainable = False\n",
        "\n",
        "        self.model.add(self.base_model)\n",
        "        \n",
        "        self.model.add(Flatten())\n",
        "\n",
        "        self.model.add(Dense(512, activation='relu'))\n",
        "        self.model.add(Dense(256, activation='relu'))\n",
        "\n",
        "        self.model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    def train_model(self, X_train, Y_train):\n",
        "\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "        #                       patience=2, min_lr=0.0000001,cooldown=1)\n",
        "        # checkpoint_best = callbacks.ModelCheckpoint(filepath='sample_data/best_model.h5', monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "        self.model.fit(X_train, Y_train, batch_size=self.batch_size, epochs=self.epochs)\n",
        "\n",
        "        print(\"Model Trained\")\n",
        "\n",
        "    def train_model_fit(self, train_data, val_data, callback):\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        self.model.fit(train_data, steps_per_epoch=self.STEP_SIZE_TRAIN, epochs=self.epochs, \n",
        "                       validation_data=val_data, validation_steps=self.STEP_SIZE_VALID, callbacks=callback)\n",
        "    \n",
        "    def train_model_gen(self, train_gen, val_gen):\n",
        "\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        self.model.fit_generator(generator=train_gen, steps_per_epoch=self.STEP_SIZE_TRAIN,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=self.STEP_SIZE_VALID,\n",
        "                    epochs=self.epochs)\n",
        "\n",
        "    def evaluate_model(self, X_test, Y_test):\n",
        "\n",
        "        loss, accuracy = self.model.evaluate(X_test, Y_test, batch_size=self.batch_size)\n",
        "        print(\"Loss: \"+str(loss))\n",
        "        print(\"Accuracy: \"+str(accuracy))\n",
        "\n",
        "    def evaluate_model_gen(self, test_gen):\n",
        "\n",
        "        self.model.evaluate_generator(generator=test_gen,steps=self.STEP_SIZE_VALID)\n",
        "\n",
        "    def evaluate_new(self, test_gen):\n",
        "\n",
        "        self.model.evaluate(generator=test_gen,steps=self.STEP_SIZE_VALID)\n",
        "\n",
        "    def save(self):\n",
        "\n",
        "        self.model.save('sample_data/mrlEyes_2018_01/model.h5')\n",
        "        print(\"Model Saved\")\n",
        "\n",
        "    def predict(self, image):\n",
        "\n",
        "        image = image.reshape((1,1, 80, 80))\n",
        "        image.astype('Float32')\n",
        "        image /= 255.0\n",
        "\n",
        "        result = self.model.predict_proba(image)\n",
        "        max_index = np.argmax(result)\n",
        "\n",
        "        return max_index, result[0](max_index)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('TensorFlow version:', tf.__version__)\n",
        "    print('Is using GPU?', tf.test.is_gpu_available())\n",
        "\n",
        "    from tensorflow.python.client import device_lib\n",
        "\n",
        "    # def get_available_devices():\n",
        "    #     local_device_protos = device_lib.list_local_devices()\n",
        "    #     return [x.name for x in local_device_protos]\n",
        "\n",
        "    # print(get_available_devices())\n",
        "\n",
        "    # with tf.device('/device:XLA_GPU:0'):\n",
        "\n",
        "    model = Model(epochs=20, batch_size=32)\n",
        "\n",
        "    # model.inputshape = (64, 64, 1)\n",
        "    \n",
        "    data_gen = ImageDataGenerator(rescale=1./255.)\n",
        "    train_gen = data_gen.flow_from_directory(directory=r\"sample_data/mrlEyes_2018_01/Train_data1/\",\n",
        "                                              target_size=(64, 64),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32,\n",
        "                                              classes = ['1', '0'],\n",
        "                                              class_mode=\"binary\",\n",
        "                                              shuffle=True)\n",
        "\n",
        "    val_gen = data_gen.flow_from_directory(directory=r\"sample_data/mrlEyes_2018_01/Val_data1/\",\n",
        "                                              target_size=(64, 64),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32,\n",
        "                                              classes = ['1', '0'],\n",
        "                                              class_mode=\"binary\",\n",
        "                                              shuffle=True)\n",
        "    \n",
        "    test_gen = data_gen.flow_from_directory(directory=r\"sample_data/mrlEyes_2018_01/Test_data1/\",\n",
        "                                              target_size=(64, 64),\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              batch_size=32,\n",
        "                                              classes = ['1', '0'],\n",
        "                                              class_mode=None,\n",
        "                                              shuffle=False)\n",
        "\n",
        "    STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
        "    STEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n",
        "    STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
        "\n",
        "    model.STEP_SIZE_TRAIN = STEP_SIZE_TRAIN\n",
        "    model.STEP_SIZE_VALID = STEP_SIZE_VALID\n",
        "    model.STEP_SIZE_TEST = STEP_SIZE_TEST\n",
        "\n",
        "    callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0000001,cooldown=1)\n",
        "    checkpoint_best = callbacks.ModelCheckpoint(filepath='sample_data/mrlEyes_2018_01/best_model.h5', monitor=\"val_accuracy\", save_best_only=True)\n",
        "    callbacks = [callback_lr, checkpoint_best]\n",
        "\n",
        "    # model.build_model()\n",
        "    # model.train_model_gen(train_gen, val_gen)\n",
        "    model.build_on_resnet()\n",
        "    model.train_model_fit(train_gen, val_gen, callbacks)\n",
        "    # model.evaluate_model_gen(test_gen)\n",
        "    # model.evaluate_new(test_gen)\n",
        "    # model.save()\n",
        "\n",
        "    # model = load_model(\"best_model.h5\")\n",
        "    # model.predict()\n",
        "    # model.evaluate_new(val_gen)\n",
        "    # model.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycDqLWtVMalB"
      },
      "source": [
        "########### Evaluate on val data ################\n",
        "\n",
        "model = load_model('sample_data/mrlEyes_2018_01/best_model.h5')\n",
        "model.evaluate(x=val_gen, steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_25rHTh-MeBx"
      },
      "source": [
        "############## Predict ################\n",
        "\n",
        "preds = model.predict(x=test_gen, verbose=1, steps=STEP_SIZE_TEST)\n",
        "actual = test_gen.classes\n",
        "file = open(\"results_new.txt\", 'w+')\n",
        "for i in range(len(preds)):\n",
        "    val = (preds[i][0], actual[i])\n",
        "    file.write(str(val))\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHQUxofdMgPB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(40,40))\n",
        "\n",
        "loses = pd.DataFrame(model.history.history)\n",
        "# loses.plot()\n",
        "loses.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfOOzn9vMngg"
      },
      "source": [
        "######### Plot accuracies ###########\n",
        "\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzjwRpiqMpzY"
      },
      "source": [
        "###### Plot loses ##################\n",
        "\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}